name: 'Airflow Services'

services:
  redis:
    image: redis:latest
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD-SHELL", "redis-cli ping | grep PONG"]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - ./redisdata:/data

  airflow-init:
    image: apache/airflow:2.8.1-python3.11
    depends_on:
      redis:
        condition: service_healthy
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@host.docker.internal:5432/airflow?options=-csearch_path%3Dairflow_schema
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@host.docker.internal:5432/airflow
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    entrypoint: /bin/bash
    command:
      - -c
      - |
        airflow db migrate
        airflow users create \
          --username admin \
          --password admin \
          --firstname admin \
          --lastname admin \
          --role Admin \
          --email admin@example.com

  airflow-webserver:
    image: apache/airflow:2.8.1-python3.11
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@host.docker.internal:5432/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@host.docker.internal:5432/airflow
      _PIP_ADDITIONAL_REQUIREMENTS: >-
        apache-airflow-providers-postgres==5.5.1
        apache-airflow-providers-google==10.3.0
        apache-airflow-providers-apache-spark==4.1.0
        astronomer-cosmos[bigquery]==1.5.1
        pandas==2.2.0
    ports:
      - "8080:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./scripts:/opt/airflow/scripts
      - ./dbt:/opt/airflow/dbt
      - ./spark:/opt/airflow/spark
      - ./config:/opt/airflow/config
      - ./resources:/opt/airflow/resources
    command: webserver

  airflow-scheduler:
    image: apache/airflow:2.8.1-python3.11
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@host.docker.internal:5432/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@host.docker.internal:5432/airflow
      _PIP_ADDITIONAL_REQUIREMENTS: >-
        apache-airflow-providers-postgres==5.5.1
        apache-airflow-providers-google==10.3.0
        apache-airflow-providers-apache-spark==4.1.0
        astronomer-cosmos[bigquery]==1.5.1
        pandas==2.2.0
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./scripts:/opt/airflow/scripts
      - ./dbt:/opt/airflow/dbt
      - ./spark:/opt/airflow/spark
      - ./config:/opt/airflow/config
      - ./resources:/opt/airflow/resources
    command: scheduler

  airflow-worker:
    image: apache/airflow:2.8.1-python3.11
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@host.docker.internal:5432/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@host.docker.internal:5432/airflow
      AIRFLOW__CELERY__WORKER_CONCURRENCY: 8
      AIRFLOW__CELERY__WORKER_PREFETCH_MULTIPLIER: 1
      AIRFLOW__CELERY__WORKER_MAX_TASKS_PER_CHILD: 100
      _PIP_ADDITIONAL_REQUIREMENTS: >-
        apache-airflow-providers-postgres==5.5.1
        apache-airflow-providers-google==10.3.0
        apache-airflow-providers-apache-spark==4.1.0
        astronomer-cosmos[bigquery]==1.5.1
        pandas==2.2.0
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./scripts:/opt/airflow/scripts
      - ./dbt:/opt/airflow/dbt
      - ./spark:/opt/airflow/spark
      - ./config:/opt/airflow/config
      - ./resources:/opt/airflow/resources
    command: celery worker

networks:
  default:
    name: airflow_network
